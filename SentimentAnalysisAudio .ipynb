{"cells":[{"cell_type":"markdown","source":["**Sentiment Analysis for Incoming Calls on Helpdesk**"],"metadata":{"id":"N2y8IRRdEVcU"}},{"cell_type":"markdown","source":["This script initiates the sentiment analysis project by importing necessary libraries for speech recognition, natural language processing, and emotion analysis. The speech_recognition library is used to convert spoken language into text, nltk is used to analyze the sentiment of the text, and NRCLex is used to determine the emotional content of the text."],"metadata":{"id":"4suEgQCyEiHh"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70233,"status":"ok","timestamp":1714579313409,"user":{"displayName":"Akshat Thakur","userId":"06848635181474892504"},"user_tz":-330},"id":"pLcVpUxG4osa","outputId":"baf62f17-0838-4d8a-f3f3-608609b7ae46"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting speechrecognition\n","  Downloading SpeechRecognition-3.10.3-py2.py3-none-any.whl (32.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (2.31.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (2024.2.2)\n","Installing collected packages: speechrecognition\n","Successfully installed speechrecognition-3.10.3\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n","Collecting NRCLex\n","  Downloading NRCLex-4.0-py3-none-any.whl (4.4 kB)\n","Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (from NRCLex) (0.17.1)\n","INFO: pip is looking at multiple versions of nrclex to determine which version is compatible with other requirements. This could take a while.\n","  Downloading NRCLex-3.0.0.tar.gz (396 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob->NRCLex) (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->NRCLex) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->NRCLex) (1.4.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->NRCLex) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->NRCLex) (4.66.2)\n","Building wheels for collected packages: NRCLex\n","  Building wheel for NRCLex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NRCLex: filename=NRCLex-3.0.0-py3-none-any.whl size=43309 sha256=5db10703ea65b435e74d0210c2564d2966668d05800f922def5c048b0d1153f3\n","  Stored in directory: /root/.cache/pip/wheels/d2/10/44/6abfb1234298806a145fd6bcaec8cbc712e88dd1cd6cb242fa\n","Successfully built NRCLex\n","Installing collected packages: NRCLex\n","Successfully installed NRCLex-3.0.0\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libasound2-dev is already the newest version (1.2.6.1-1ubuntu1).\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","Suggested packages:\n","  portaudio19-doc\n","The following NEW packages will be installed:\n","  libportaudio2 libportaudiocpp0 portaudio19-dev\n","0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 188 kB of archives.\n","After this operation, 927 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n","Fetched 188 kB in 1s (200 kB/s)\n","Selecting previously unselected package libportaudio2:amd64.\n","(Reading database ... 121920 files and directories currently installed.)\n","Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n","Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n","Selecting previously unselected package libportaudiocpp0:amd64.\n","Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n","Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n","Selecting previously unselected package portaudio19-dev:amd64.\n","Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n","Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n","Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n","Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n","Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","Collecting pyaudio\n","  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m872.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pyaudio\n","  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyaudio: filename=PyAudio-0.2.14-cp310-cp310-linux_x86_64.whl size=63863 sha256=6f6942de1c5ca1217ec15a33fedfff9c77f8b27511ab3168fb6b656db6526011\n","  Stored in directory: /root/.cache/pip/wheels/d6/21/f4/0b51d41ba79e51b16295cbb096ec49f334792814d545b508c5\n","Successfully built pyaudio\n","Installing collected packages: pyaudio\n","Successfully installed pyaudio-0.2.14\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["!pip install speechrecognition\n","!pip install nltk\n","!pip install NRCLex\n","!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n","!pip install pyaudio\n","\n","import nltk\n","nltk.download('vader_lexicon')"]},{"cell_type":"markdown","source":["The script provides two modes of operation: one that allows the user to speak directly into the microphone for real-time sentiment analysis, and another that accepts an audio file for sentiment analysis. The results, including the sentiment score, sentiment label, and emotion scores, are then printed to the console.\n","\n","This code is designed to perform sentiment analysis on spoken language. It processes speech, either directly spoken into the microphone or from an audio file, and interprets the sentiment or mood conveyed. The program determines whether the overall sentiment of the speech is positive, negative, or neutral.\n","\n","Furthermore, it delves deeper into the emotional content of the speech, identifying specific emotions such as joy, sadness, or anger. Thus, the output of this code provides a comprehensive understanding of not just the content of the speech, but also the emotional context and sentiment it carries. This can be particularly useful in applications where understanding the tone and mood of the speech is as important as understanding the content itself."],"metadata":{"id":"wUVge0ahECvE"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2BjTe04l5EWM","outputId":"7a45b827-15d3-4d7d-f259-f18d47abb2e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["1. Speak for audio input\n","2. Provide the path for a file for audio input\n","3. Exit\n"]}],"source":["import speech_recognition as sr\n","import nltk\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","from nrclex import NRCLex\n","\n","def analyze_sentiment(sentence):\n","    sia = SentimentIntensityAnalyzer()\n","    sentiment_scores = sia.polarity_scores(sentence)\n","    compound_score = sentiment_scores['compound']\n","    nrc_lex = NRCLex(sentence)\n","    emotion_scores = nrc_lex.raw_emotion_scores\n","    if compound_score > 0:\n","        sentiment_label = 'Positive'\n","    elif compound_score == 0:\n","        sentiment_label = 'Neutral'\n","    else:\n","        sentiment_label = 'Negative'\n","\n","    return {\n","        'compound_score': compound_score,\n","        'sentiment_label': sentiment_label,\n","        'emotion_scores': emotion_scores\n","    }\n","\n","def analyze_audio_from_microphone():\n","    recognizer = sr.Recognizer()\n","    with sr.Microphone() as source:\n","        audio = recognizer.listen(source)\n","\n","    try:\n","        text = recognizer.recognize_google(audio)\n","        result = analyze_sentiment(text)\n","        print(f\"Sentence: {text}\\nCompound Score: {result['compound_score']}\\nSentiment Label: {result['sentiment_label']}\\nEmotion Scores: {result['emotion_scores']}\\n\")\n","    except sr.UnknownValueError:\n","        print(\"Google Web Speech API could not understand audio\")\n","    except sr.RequestError as e:\n","        print(\"Could not request results from Google Web Speech API; {0}\".format(e))\n","\n","def analyze_audio_from_file(wave_file_path):\n","    recognizer = sr.Recognizer()\n","    with sr.AudioFile(wave_file_path) as source:\n","        audio = recognizer.record(source)\n","\n","    try:\n","        text = recognizer.recognize_google(audio)\n","        result = analyze_sentiment(text)\n","        print(f\"Sentence: {text}\\nCompound Score: {result['compound_score']}\\nSentiment Label: {result['sentiment_label']}\\nEmotion Scores: {result['emotion_scores']}\\n\")\n","    except sr.UnknownValueError:\n","        print(\"Google Web Speech API could not understand audio\")\n","    except sr.RequestError as e:\n","        print(\"Could not request results from Google Web Speech API; {0}\".format(e))\n","\n","def main():\n","    while True:\n","        print(\"1. Speak for audio input\")\n","        print(\"2. Provide the path for a file for audio input\")\n","        print(\"3. Exit\")\n","        choice = input(\"Enter your choice: \\n\")\n","\n","        if choice == '1':\n","            analyze_audio_from_microphone()\n","        elif choice == '2':\n","            wave_file_path = input(\"Enter the path of the audio file: \")\n","            analyze_audio_from_file(wave_file_path)\n","        elif choice == '3':\n","            break\n","        else:\n","            print(\"Invalid choice. Please enter 1, 2, or 3.\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN8qrbUCm9ipXJyNOMhnpWW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}